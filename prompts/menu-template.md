# Interactive Menu Template

## BordneAI Research Engine: Domain Selection Menu

Welcome to the BordneAI Research Engine. This guided menu helps you explore evidence-based analysis in historically sensitive and institutionally complex domains.

---

## Select a Domain to Explore

### Option 1: Nuclear History & NC3

**Description:** U.S. nuclear weapons history, particularly Okinawa and Pacific deployments; Nuclear Command & Control & Communications (NC3) protocols; near-miss incidents; institutional secrecy norms around deterrence.

**Key Questions This Domain Answers:**
- What do declassified sources tell us about nuclear weapons deployment history?
- How do we reason about sealed NC3 records without speculation?
- What institutional incentives explain classification of nuclear policy?

**Available Evidence (T1):**
- ~500+ declassified State Department cables on nuclear policy
- Military historical records covering 1945–present
- Congressional hearing records (Armed Services, Foreign Relations committees)

**Sourcing Standards:** High (strong declassified baseline; significant T1 material available)

**Typical Queries:** "What happened in Incident X?", "Why are NC3 details sealed?", "What does historical precedent suggest about current status?"

**[Explore Nuclear History Domain]**

---

### Option 2: Intelligence & Oversight

**Description:** Electoral history and institutional analysis; declassified intelligence assessments; Congressional oversight records; intelligence activities disclosed via FOIA; institutional analysis of how intelligence systems work.

**Key Questions This Domain Answers:**
- What did declassified intelligence assessments conclude?
- How reliable are institutional assessments on contested topics?
- What does the record show about intelligence oversight and accountability?

**Available Evidence (T1):**
- Declassified Intelligence Community Assessments (ICAs)
- Congressional hearing records (open sessions)
- Congressional Research Service (CRS) reports
- FOIA-released intelligence documents

**Sourcing Standards:** Medium-High (good declassified baseline; some material withheld for OPSEC)

**Typical Queries:** "What did the 2016 intelligence assessment conclude?", "How do institutions assess controversial events?", "What does declassified evidence show about Y?"

**[Explore Intelligence & Oversight Domain]**

---

### Option 3: UAP/UFO/USO

**Description:** Unidentified Aerial Phenomena; declassified military sensor data and kinematics analysis; physics constraints on reported behavior; pilot testimony; institutional responses to UAP reports.

**Key Questions This Domain Answers:**
- What can physics constraints tell us about reported UAP kinematics?
- How do we evaluate sensor data quality and false positive rates?
- What competing hypotheses fit declassified evidence?

**Available Evidence (T1):**
- Declassified military video and radar data
- Congressional hearing records (recent)
- DoD incident reports (partially declassified)
- Sensor technical specifications

**Sourcing Standards:** Medium (growing declassification; large evidence gaps remain; significant sealed material)

**Typical Queries:** "What does the Gimbal video show?", "Could X acceleration be physically possible?", "What are competing explanations?"

**[Explore UAP/UFO/USO Domain]**

---

### Option 4: 3i_atlas_core

**Description:** [Scope and description to be defined per implementation]

**Key Questions This Domain Answers:**
- [Specify typical questions]

**Available Evidence (T1):**
- [Specify available declassified material]

**Sourcing Standards:** [Specify confidence level of available evidence]

**Typical Queries:** [Specify example queries]

**[Explore 3i_atlas_core Domain]**

---

### Option 5: Custom Query

**Description:** Not sure which domain fits your question? Or have a question that spans multiple domains?

**How This Works:**
1. Describe your question or topic
2. System will identify relevant domains and sourcing frameworks
3. Response will apply appropriate governance rules
4. Analysis will integrate T1/T2/T3 evidence as available

**Examples of cross-domain queries:**
- "How do institutional incentives explain both nuclear secrecy and intelligence classification?"
- "What role did intelligence assessments play in decisions about weapons deployment?"
- "How do physics constraints and institutional behavior combine to explain UAP patterns?"

**[Submit Custom Query]**

---

## How to Use This Engine

### Sourcing Hierarchy (T1–T4)

All responses use a four-tier sourcing system:

- **T1 (Highest Confidence):** Declassified documents, official records, primary sources
- **T2 (Medium Confidence):** Peer-reviewed research, published analysis, institutional studies
- **T3 (Medium-Low Confidence):** Historical syntheses, journalism, secondary accounts
- **T4 (Lowest Confidence):** Testimony, eyewitness accounts (always flagged; never sufficient alone)

### What Responses Include

Every response will:
1. ✅ Break down evidence by tier (what's T1, T2, T3, T4?)
2. ✅ Cite sources (you can verify independently)
3. ✅ Flag competing hypotheses with confidence ranges
4. ✅ Acknowledge sealed records and why they're sealed
5. ✅ Use precise language (no hedging: "70% likely X" not "perhaps X")
6. ✅ Show reasoning (why does this interpretation outweigh that one?)

### Governance Rules

This engine respects three core principles:

1. **Verifiability:** All claims traceable to sources
2. **Structural Secrecy:** Sealed records explained without assuming content
3. **Competing Hypotheses:** Uncertainty quantified, not hidden

See `/GOVERNANCE.md` for full rules.

---

## Quick Reference

### What This Engine Does Well

- ✅ Reason about incomplete, contested, or classified information
- ✅ Distinguish declassified facts from interpretation
- ✅ Respect institutional secrecy without assuming conspiracy
- ✅ Present multiple competing explanations with confidence levels
- ✅ Apply physics/institutional constraints to bound plausibility
- ✅ Flag testimony as testimony (not treat it as fact)

### What This Engine Won't Do

- ❌ Assume sealed records definitely contain specific content
- ❌ Use hedging language instead of confidence ranges
- ❌ Present single hypothesis as only explanation
- ❌ Ignore physics or institutional constraints
- ❌ Make partisan inferences without T1/T2 evidence
- ❌ Claim certainty about unknowable matters

---

## Feedback & Corrections

See something wrong? Have a suggestion?

- **Flag errors:** Use GitHub Issues or email (see `/GOVERNANCE.md`)
- **Propose domains:** Contact BordneAI@bordne.com
- **Security concerns:** Email BordneAI@bordne.com (subject: "SECURITY")

---

## Documentation

For deeper understanding:

- **Sourcing guide:** `/SOURCING_PROFILE_V2.1.md`
- **Governance rules:** `/GOVERNANCE.md`
- **Domain methodology:** `/docs/domains.md`
- **Sealed records reasoning:** `/docs/structural-secrecy.md`
- **Real examples:** `/docs/examples.md`
- **System architecture:** `/SYSTEM_PROMPT-v3.0.md`

---

**Version:** BordneAI Research Engine v3.0-alpha
**Last Updated:** 2025-11-17
**License:** CC BY 4.0 (attribution required)
**Maintained By:** David Bordne
