# Framework Examples: Methodology in Action

---

## Introduction

These examples demonstrate how tiered sourcing and entropy levels apply to contested topics. All scenarios are **generic and hypothetical**‚Äîdesigned to illustrate methodology, not analyze real incidents.

Each example shows:
- **Query:** The question asked
- **Governance Checkpoints:** Which rules applied
- **System Response:** How the framework structures the answer
- **Key Lessons:** What this illustrates about the framework

---

## Example 1: Lightweight Mode ‚Äî Simple Factual Question

### Query
"What is the capital of France?"

### Governance Checkpoints
- ‚úÖ Entropy: L1 (simple, well-documented, no conflict)
- ‚úÖ Mode: Lightweight (low-stakes, clear evidence)
- ‚úÖ Tiers: T1 available (official documents)

### System Response

The capital of France is Paris. This is established in French constitutional documents and international recognition agreements.

### Key Lessons
- Low-entropy questions need minimal structure
- Implicit sourcing is acceptable for L1 topics
- Lightweight mode is efficient for clear facts
- Not every claim requires elaborate documentation

---

## Example 2: Lightweight Mode ‚Äî Casual Lookup

### Query
"What are some free video editing software options?"

### Governance Checkpoints
- ‚úÖ Entropy: L1-L2 (clear options, some subjective judgment)
- ‚úÖ Mode: Lightweight (low-stakes, opinion is acceptable)
- ‚úÖ Tiers: T3 primary (reviews and recommendations)

### System Response

Several free options exist:

- **DaVinci Resolve:** Professional-grade, free version, supports 4K
- **OpenShot:** Simple, cross-platform, good for beginners
- **Shotcut:** Lightweight, open-source, supports many formats
- **CapCut:** Mobile-first, increasingly popular for social media

Your choice depends on complexity needs and platform. Professional editors often prefer DaVinci Resolve; beginners find OpenShot intuitive.

### Key Lessons
- Opinion questions can be lightweight even with multiple valid answers
- No need for ‚úÖ/üîç distinction when stakes are low
- Sourcing can be implicit ("multiple editors recommend...")
- Simple recommendation structure is acceptable

---

## Example 3: Structured Mode ‚Äî Contested Historical Question

### Query
"How do historians assess competing accounts of a major historical event where multiple credible sources exist?"

*(Generic example: imagine a historical event with conflicting contemporary documents)*

### Governance Checkpoints
- ‚úÖ Entropy: L3 (multiple interpretations, good documentation)
- ‚úÖ Mode: Structured (historical dispute, multiple credible accounts)
- ‚úÖ Tiers: T1 (primary documents), T2 (academic analysis), T3 (historical synthesis)
- ‚úÖ High-stakes identification: Academic integrity, educational accuracy

### System Response

üß™ **Header**
- **Entropy Level:** L3
- **Size:** Medium
- **Mode:** Structured
- **Source Mix:** T1 primary documents available; T2 analysis provides competing interpretations
- **Confidence:** Medium (sources agree on core facts but diverge on causation and significance)
- **As Of:** 2025

‚úÖ **Verified Facts**
- Official records document [specific claim] (T1, official archive, dated 1850, confidence: very_high)
- Contemporaneous witness account documents [related claim] (T1, archival record, dated 1850, confidence: high‚Äîeyewitness account, but scope-limited)
- Subsequent scholarship consensus identifies [third claim] as established (T2, peer-reviewed history journal, dated 2005, consensus view, confidence: high)

üîç **Analysis / Interpretations**
Historians diverge on causation:
- **Interpretation A:** [Account 1] and [Account 2] indicate primary driver was [cause X]. This interpretation emphasizes the documented timing and sequence of events.
- **Interpretation B:** Later scholarship argues [cause Y] was more significant, supported by evidence of [specific institutional incentive].

Both interpretations fit available T1 evidence but emphasize different factors.

üåÄ **Testimony & Experiential Input**
- One school of thought (represented by [T4_named scholar] in 1990s) argues [position A], though this has been somewhat superseded by newer T2 consensus.
- Some contemporary accounts (T1, witnesses) suggest [alternative detail], though this is not emphasized in modern consensus interpretation.

‚ö†Ô∏è **Structural Context / Limitations**
- This assessment reflects available published sources; additional archival research might surface new primary documents
- Interpretation depends partly on philosophical assumptions about causation (not empirically resolvable)
- Later accounts may be influenced by political motivations of their era
- Missing evidence: [specific types of records that remain unclear or lost]

üõ†Ô∏è **Next Steps**
- For deeper understanding: consult the academic consensus review in [academic source]
- Declassification of [specific records category, if applicable] would likely clarify [specific dispute]
- The historiographical debate is instructive precisely because it shows how reasonable scholars interpret the same evidence differently

### Key Lessons
- Structured mode clearly separates facts (‚úÖ) from interpretations (üîç)
- Competing T1 sources are presented without false neutrality
- T2 consensus is weighted appropriately
- Limitations are acknowledged (interpretation is not fact-determinable)
- Framework enables learning from disagreement, not just resolving it

---

## Example 4: Structured Mode ‚Äî Tier Conflict (T1 vs T2)

### Query
"How does the system handle when official records conflict with peer-reviewed analysis?"

*(Generic example: imagine official documentation states policy A, but academic analysis argues policy A produces outcome B, which contradicts official claims)*

### Governance Checkpoints
- ‚úÖ Entropy: L3-L4 (disagreement between high tiers)
- ‚úÖ Mode: Structured (tier conflict requires explicit handling)
- ‚úÖ BAAM Weighting applied: T1 > T2, but reasons for divergence examined
- ‚úÖ Temporal Anchoring: Both claims dated

### System Response

üß™ **Header**
- **Entropy Level:** L3
- **Size:** Medium
- **Mode:** Structured
- **Source Mix:** T1 and T2 in direct conflict; requires careful weighing
- **Confidence:** Medium (T1 authority weighed against T2 credibility and methodology)
- **As Of:** 2025

‚úÖ **Verified Facts**
- Official agency statement: [claim X] (T1, official document, dated 2020, confidence: very_high for what they stated)
- Peer-reviewed analysis: research indicates [contradictory outcome] (T2, academic meta-analysis, dated 2023, confidence: high for research quality)

üîç **Analysis / Interpretations**
These sources diverge for potentially explicable reasons:
- The official statement was based on [specific methodology or time period]
- The academic analysis used [different measurement or longer time series]
- Possible explanations for divergence:
  1. Methodology difference: Official statement measured [X], research measured [Y]
  2. Time difference: Official statement predated 2022 research; conditions may have evolved
  3. Scope difference: Official statement addressed [narrow scope]; research addressed [broader scope]

**Confidence distribution:**
- T1 official claim about what policy stated: extremely_high
- T1 official claim about effects of policy: medium-high (official methodology may have limitations)
- T2 academic claim about research findings: high
- T2 academic claim about policy effectiveness: medium (research may not capture all real-world effects)

üåÄ **Testimony & Experiential Input**
- Some practitioners report [observation consistent with T2 research], though this is anecdotal (T4_named practitioners, confidence: low_to_medium)

‚ö†Ô∏è **Structural Context / Limitations**
- This disagreement is common in policy analysis: official accounts and independent research often diverge
- Key unknown: Whether official data [specific measurement methodology] would show same result if applied to longer time series
- Missing: [specific types of data that would clarify the divergence]

üõ†Ô∏è **Next Steps**
- Request official methodology for [specific measurement]
- Future research addressing [specific gap] would clarify whether divergence reflects method or substance
- Both sources contain truth: official documentation is accurate about [what they documented]; research findings are accurate about [what they measured]

### Key Lessons
- Tier conflict does not mean one source is wrong; it means they answer different questions
- BAAM weighting doesn't hide conflict; it explains it
- Methodology differences are documented reasons for divergence
- High-tier sources can simultaneously be authoritative in their domain and limited in their scope

---

## Example 5: Structured Mode ‚Äî Limited Evidence (High Entropy)

### Query
"How does the framework approach a topic with significant evidence gaps?"

*(Generic example: a technical question where only partial evidence exists)*

### Governance Checkpoints
- ‚úÖ Entropy: L4 (significant gaps, limits confidence ceiling)
- ‚úÖ Mode: Structured (high entropy requires full scaffolding)
- ‚úÖ Self-Check: Scan for overconfidence (resist overconfidence with gaps)
- ‚úÖ Refusal of unanchored speculation

### System Response

üß™ **Header**
- **Entropy Level:** L4
- **Size:** Medium
- **Mode:** Structured
- **Source Mix:** T1/T2 available for [specific aspects]; gaps for [other aspects]
- **Confidence:** Low to Medium (assessment limited by significant evidence gaps)
- **As Of:** 2025

‚úÖ **Verified Facts**
- Research confirms [specific narrow claim] (T2, peer-reviewed study, dated 2023, confidence: high‚Äînarrow scope)
- Official data available for [metric X] (T1, published annually, dated 2024, confidence: very_high)

üîç **Analysis / Interpretations**
Broader claims go beyond available evidence:
- Hypothesis: [broader claim] might be true *if* [conditions X, Y, Z]
- Conditional reasoning: Given documented [fact A], scenario [scenario] would follow; however, [fact A] may not be typical

**What we cannot conclude yet:**
- Whether pattern observed in [documented case] generalizes beyond [specific scope]
- Whether [outcome Y] would result from [action X] in current conditions
- Whether [mechanism Z] explains [observation] (alternative mechanisms plausible)

üåÄ **Testimony & Experiential Input**
- Some practitioners report [observation], though systematic data do not yet confirm prevalence (T4_named practitioners, confidence: low_to_medium‚Äîuseful for generating hypotheses)

‚ö†Ô∏è **Structural Context / Limitations**
**Key evidence gaps:**
- No T1 data available for [specific variable] ‚Äî this is a major limitation
- T2 research is limited to [specific population/context] ‚Äî generalization uncertain
- Time-sensitive: Most recent data is from [date]; conditions may have changed
- [Specific methodological constraint] limits confidence

**Central unknowns:**
1. Whether [pattern X] holds in [broader context]
2. Whether [mechanism Y] is actually operative or coincidental
3. What counterfactuals would show (no baseline comparison available)

üõ†Ô∏è **Next Steps**
**To raise confidence, we would need:**
- T1 data on [specific metric] for [time period or population]
- T2 research addressing [specific question] with [specific methodology]
- Comparison group or longitudinal data

**Until then:**
- Treat [broader claim] as hypothesis, not established fact
- Acknowledge uncertainty ceiling: "Confidence cannot exceed medium until [specific evidence type] is available"
- Monitor [specific developments] for new evidence

### Key Lessons
- L4 entropy honest about limits rather than confident beyond evidence
- Unknowns are listed explicitly
- Hypotheses are labeled as conditional, not concluded
- Framework specifies what evidence would change assessment
- Overconfidence is prevented by mapping gaps

---

## Example 6: Structured Mode ‚Äî Suppression & Secrecy Context

### Query
"How does the framework discuss topics where some information is classified or sealed?"

*(Generic example: a policy question where official records are partially declassified)*

### Governance Checkpoints
- ‚úÖ Entropy: L3-L4 (gaps due to classification, not conspiracy)
- ‚úÖ Mode: Structured (gaps require explicit handling)
- ‚úÖ Suppression Guardrail: Explain incentives, don't assert suppression without evidence
- ‚úÖ Temporal Anchoring: Declassification dates specified

### System Response

üß™ **Header**
- **Entropy Level:** L3
- **Size:** Medium
- **Mode:** Structured
- **Source Mix:** T1 available (partially declassified); T1 gaps due to classification
- **Confidence:** Medium (high for what is documented; lower for unreleased portions)
- **As Of:** 2025

‚úÖ **Verified Facts**
- Declassified document dated [YEAR], released [YEAR]: [specific claim] (T1, official source, declassified, confidence: very_high)
- Portions classified at [classification level] remain unreleased (T1, official record, confidence: very_high)

üîç **Analysis / Interpretations**
**Why records might remain sealed:**
- Standard [classification category] typically involves [topic area] for [standard reasons: national security, trade secret, privacy, ongoing enforcement]
- Historical precedent: Similar [policy area] records remained sealed for [time period]; declassification followed
- Institutional incentives: [Agency] has standard practice of protecting [information type]

**This reflects structural secrecy, not proof of suppression.**

**What declassified portions tell us:**
- Released documents confirm [verified fact above]
- Gaps in released documents suggest [topic area] was sensitive for [explicable reason]
- Scope of redaction (what was removed) indicates [specific categories] were protected

**What sealed documents likely contain:**
- Plausibly: [evidence-based speculation based on pattern from similar declassifications]
- Unlikely absent new evidence: [speculation without T1/T2 support]

üåÄ **Testimony & Experiential Input**
- Some former officials have testified (public record) that [specific detail] was [T4_named official testimony], though full context remains classified
- Anonymous sources online claim [alternative detail], though these cannot be verified (T4_anon, confidence: low)

‚ö†Ô∏è **Structural Context / Limitations**
**What we know:**
- Content of declassified documents ‚úÖ
- Fact of ongoing classification ‚úÖ
- Classification category and likely topic areas ‚úÖ

**What we don't know:**
- Specific content of sealed documents ‚ùå
- Whether sealed documents confirm or contradict declassified information ‚ùå
- Official reasons for classification (not always stated) ‚ùå

**Why absence of evidence is not evidence of suppression:**
- Sealed records are normal, not exceptional
- Absence of evidence ‚â† evidence of hidden truth; it may simply mean records were not created or followed normal classification procedures
- Confirmed suppression requires T1 evidence (whistleblower testimony, official admission, research confirming deception)

**What would change assessment:**
- Declassification of [specific records] would show [either confirming or contradicting the analysis]
- Official admission or documented pattern of deception would raise suppression hypothesis from plausible to confirmed
- Research evidence of [outcome Y] would be inconsistent with official claims (would be T2 evidence of deception)

üõ†Ô∏è **Next Steps**
- Monitor declassification schedules for [agency/category] for new releases
- Research [specific question] using other T1 sources (FOIA requests, other agencies, etc.)
- When records are declassified, update assessment; structural silence often reflects institutional practice, not hidden truth

### Key Lessons
- Secrecy is explicable through institutional incentives, not conspiracy
- Declassified records are treated as T1; unreleased records are acknowledged gaps
- Framework distinguishes between "not yet declassified" (structural secrecy) and "definitely hidden" (requires evidence)
- Absence of evidence is discussed honestly: it's a limit on confidence, not proof of suppression
- What would change the assessment is specified explicitly

---

## Example 7: Structured Mode ‚Äî High-Stakes Topic (Medical/Legal)

### Query
"[Hypothetical health-related question about treatment options]"

### Governance Checkpoints
- ‚úÖ Entropy: L4 (medical claims are high-stakes)
- ‚úÖ Mode: Structured (required for medicine)
- ‚úÖ Disclaimer applied: "For educational purposes only"
- ‚úÖ Professional consultation recommended
- ‚úÖ Tier distribution: T1 (clinical data), T2 (research), T4 (patient experience)

### System Response

üß™ **Header**
- **Entropy Level:** L4
- **Size:** Medium
- **Mode:** Structured
- **Source Mix:** T1/T2 primary (clinical data, research); T4 secondary (patient experience)
- **Confidence:** Medium to High (evidence-based, but individual factors affect outcomes)
- **As Of:** 2025
- **‚ö†Ô∏è Disclaimer:** *This is educational and informational. It is not medical advice. Consult a qualified healthcare provider before making treatment decisions. Individual circumstances vary; what works for one person may not apply to another.*

‚úÖ **Verified Facts**
- Clinical trials document [specific outcome] for [specific treatment] (T1, FDA records / peer-reviewed trial data, dated 2024, confidence: very_high for documented population)
- Peer-reviewed meta-analysis concludes [synthesis of research] (T2, systematic review, dated 2023, confidence: high for research-based conclusion)
- Current standard of care [specific guideline] (T1, professional medical guidelines, dated 2025, confidence: very_high)

üîç **Analysis / Interpretations**
**How evidence applies to individual decisions:**
- Evidence shows [treatment] is effective for [specific population]
- Individual variation is significant: factors like [factor A], [factor B], and [factor C] affect individual outcomes
- Trade-offs include: [benefit X] vs. [risk Y]

**Conditional reasoning:**
- If patient has [condition A], evidence suggests [approach X]
- If patient has [comorbidity B], evidence suggests [different consideration]

üåÄ **Testimony & Experiential Input**
- Patient experiences vary: some report [positive outcome] (T4_anon patient reports, confidence: low for generalization, useful for understanding range of experiences)
- Healthcare practitioners report [observed pattern] (T4_named practitioners, confidence: low_to_medium‚Äîanecdotal, not systematic data)

‚ö†Ô∏è **Structural Context / Limitations**
**Research limitations:**
- Clinical trials typically involve [specific age range, demographic, health status] ‚Äî your situation may differ
- Most recent data is from [date]; longer-term effects [may/may not be] understood
- Comparison research: [alternative approaches] have been studied in [specific populations]

**What is unknown:**
- Long-term outcomes beyond [time period when data ends]
- Outcomes in [specific population] not well-studied
- [Specific interaction] with [other factor] not fully characterized

**Why you need professional judgment:**
- Your specific health history, genetics, and circumstances matter
- Risk tolerance is individual
- Alternative approaches have different trade-offs
- Professional can assess factors this framework cannot

üõ†Ô∏è **Next Steps**
**Consult your healthcare provider with:**
- Specific treatment options you're considering (bring research if interested)
- Your medical history, current medications, and comorbidities
- Questions about how published evidence applies to your specific situation
- Uncertainties and trade-offs you want to understand

**For deeper research:**
- [Specific peer-reviewed source] provides detailed evidence on [specific question]
- [Professional organization] guidelines address [specific population]
- Ask your provider about [specific research question] relevant to your situation

**This assessment will evolve as:**
- New research emerges
- Your health circumstances change
- New treatment options become available

### Key Lessons
- High-stakes topics require explicit disclaimer + professional consultation recommendation
- Evidence-based assessment does not substitute for professional judgment
- Individual variation is acknowledged (medicine is not one-size-fits-all)
- T1/T2 evidence about populations is distinguished from assessment of individual cases
- Framework clarifies what healthcare provider judgment is needed for

---

## Summary: What These Examples Illustrate

| Example | Key Concept | Lesson |
|---------|------------|--------|
| 1 & 2 | Lightweight Mode | Low-entropy topics need minimal structure; implicit sourcing acceptable |
| 3 | Structured Mode + Competing Interpretations | Same facts can support multiple interpretations; framework clarifies how |
| 4 | Tier Conflict | T1 vs. T2 conflict doesn't mean error; methodology differences are explicable |
| 5 | Evidence Gaps | Honest about unknowns; specifies what evidence would change assessment |
| 6 | Suppression & Secrecy | Structural secrecy explained through incentives; suppression requires evidence |
| 7 | High-Stakes + Professional Judgment | Evidence-based assessment complementary to, not substitute for, professional judgment |

**Core principle across all examples:** The framework governs *reasoning*, not *conclusions*. The same process applied to any domain reveals how evidence is treated and where uncertainty lies.

